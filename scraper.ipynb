{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSION FOR DATA ENGINEERING CODING ROUND - TOPOS\n",
    "  \n",
    "*Author: Ajinkya Sheth  \n",
    "University of Washington, Seattle  \n",
    "ajinkya@uw.edu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rubric\n",
    "Topos is using AI to develop a holistic understanding of location. We are looking for engineers who are curious and creative in the way they approach data. Assignment tests your ability to move from an open-ended prompt to a result that illuminates a facet (or facets) of the data that you find intriguing. We will be reviewing your work to understand the way you approach problems generally, the way you write code, and your creativity working with data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt\n",
    "The goal of this assignment is to demonstrate your ability to capture unconventional datasets, clean and store them.\n",
    "\n",
    "Write a scraper in either python or NodeJS to collect data from Wikipedia about the top cities in the United States. The fields you collect, as well as the volume of data is up to you, but ideally you add additional data beyond the initial table, such as data found on the individual city pages, or other sources of your choice. The final format should be a CSV file that is ready to be uploaded to a BigQuery table. Please read Bigquery’s Manual to prepare your CSV in the right format. Intermediary steps, environments or processes necessary to run the scraper should be documented in code as well as a Readme.md and hosted on github in a repo devoted to this assignment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "This web-scraper is my submission to Topos coding round for the Data Engineering Internship.  \n",
    "It fetches the population data of top 314 U.S. Cities from Wikipedia.  \n",
    "To be specific, from the below link:  \n",
    "https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population\n",
    "\n",
    "Additionally, it fetches the historical population trend from each of the top 314 cities by scraping the sub-links from the above url.  \n",
    "\n",
    "There are some cities (for example: Anaheim, California) where the historical population is not present in the Wikipedia webpage. In such cases, the program will notify the user.  \n",
    "\n",
    "Ultimately, we get two tables:  \n",
    "1. cities_main which contains population of top 314 cities\n",
    "2. cities_hist which contains historical population trend of top 314 cities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. cities_main table\n",
    "Fetches the data from https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population  \n",
    "Snapshot below:  \n",
    "\n",
    "![alt text](main.png \"List of cities by population\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Set-up BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_United_States_cities_by_population'\n",
    "domain='https://en.wikipedia.org'\n",
    "req = urllib.request.urlopen(url)\n",
    "article = req.read().decode()\n",
    "\n",
    "# Load article, turn into soup and get the <table>s.\n",
    "soup = BeautifulSoup(article, 'html.parser')\n",
    "tables = soup.find_all('table', class_='wikitable sortable')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Get table headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search through the tables for the one with the headings we want.\n",
    "ths = tables[0].find_all('th')\n",
    "headings=[]\n",
    "for th in ths:\n",
    "    colspan=1\n",
    "    if th.attrs:\n",
    "        colspan=int(th.attrs['colspan'])\n",
    "    header_text=th.text.strip()\n",
    "    if th.find('sup'):\n",
    "        header_text=header_text.replace(th.find('sup').text.strip(),\"\")\n",
    "    if colspan!=1:\n",
    "        for i in range(colspan):\n",
    "            headings.append(header_text+\" \"+str(i+1))\n",
    "    else:\n",
    "        headings.append(header_text)\n",
    "headings.append('Link')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Get Table Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data=[]\n",
    "for tr in tables[0].find_all('tr'):\n",
    "    tds = tr.find_all('td')\n",
    "    if not tds:\n",
    "        continue\n",
    "    row=[]\n",
    "    for td in tds:\n",
    "        td_text=td.text.strip()\n",
    "        if td.find('sup'):\n",
    "            td_text=td_text.replace(td.find('sup').text.strip(),\"\")\n",
    "        row.append(td_text)\n",
    "    row.append(domain+tds[1].find('a').get('href'))\n",
    "    table_data.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Create a dataframe from table_data and headings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_main=pd.DataFrame(table_data,columns=headings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Clean and Rearrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: stripAlpha\n",
    "Parameters:\n",
    "    dataframe: dataframe \n",
    "    column_list: List of column names\n",
    "Returns:\n",
    "    nothing\n",
    "Description:\n",
    "    strips non-numeric characters from entire columns in a dataframe\n",
    "    modifies the dataframe directly\n",
    "'''\n",
    "def stripAlpha(dataframe,column_list):\n",
    "    for col in column_list:\n",
    "        if col in list(dataframe):\n",
    "            dataframe[col]=dataframe[col].str.replace('[^0-9]','')\n",
    "        else:\n",
    "            print(str(col)+' not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_dict={\"2016 land area 1\":\"2016 land area (sq miles)\",\n",
    "            \"2016 land area 2\":\"2016 land area (sq km)\",\n",
    "            \"2016 population density 1\":\"2016 population density (sq miles)\",\n",
    "            \"2016 population density 2\":\"2016 population density (sq km)\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_main=cities_main.rename(columns=rename_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripAlpha(cities_main,['2018estimate','2010Census','2016 land area (sq miles)', '2016 land area (sq km)',\n",
    " '2016 population density (sq miles)',\n",
    " '2016 population density (sq km)',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rearrange_column=['City','2018rank','State','2018estimate','2010Census','Change','2016 land area (sq miles)',\n",
    "'2016 land area (sq km)','2016 population density (sq miles)','2016 population density (sq km)','Location','Link']\n",
    "cities_main=cities_main[rearrange_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>2018rank</th>\n",
       "      <th>State</th>\n",
       "      <th>2018estimate</th>\n",
       "      <th>2010Census</th>\n",
       "      <th>Change</th>\n",
       "      <th>2016 land area (sq miles)</th>\n",
       "      <th>2016 land area (sq km)</th>\n",
       "      <th>2016 population density (sq miles)</th>\n",
       "      <th>2016 population density (sq km)</th>\n",
       "      <th>Location</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York City</td>\n",
       "      <td>1</td>\n",
       "      <td>New York</td>\n",
       "      <td>8398748</td>\n",
       "      <td>8175133</td>\n",
       "      <td>+2.74%</td>\n",
       "      <td>3015</td>\n",
       "      <td>7809</td>\n",
       "      <td>28317</td>\n",
       "      <td>10933</td>\n",
       "      <td>40°39′49″N 73°56′19″W﻿ / ﻿40.6635°N 73.9387°W﻿...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/New_York_City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>2</td>\n",
       "      <td>California</td>\n",
       "      <td>3990456</td>\n",
       "      <td>3792621</td>\n",
       "      <td>+5.22%</td>\n",
       "      <td>4687</td>\n",
       "      <td>1139</td>\n",
       "      <td>8484</td>\n",
       "      <td>376</td>\n",
       "      <td>34°01′10″N 118°24′39″W﻿ / ﻿34.0194°N 118.4108°...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Los_Angeles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>3</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>2705994</td>\n",
       "      <td>2695598</td>\n",
       "      <td>+0.39%</td>\n",
       "      <td>2273</td>\n",
       "      <td>5887</td>\n",
       "      <td>11900</td>\n",
       "      <td>4600</td>\n",
       "      <td>41°50′15″N 87°40′54″W﻿ / ﻿41.8376°N 87.6818°W﻿...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Houston</td>\n",
       "      <td>4</td>\n",
       "      <td>Texas</td>\n",
       "      <td>2325502</td>\n",
       "      <td>2100263</td>\n",
       "      <td>+10.72%</td>\n",
       "      <td>6375</td>\n",
       "      <td>16511</td>\n",
       "      <td>3613</td>\n",
       "      <td>1395</td>\n",
       "      <td>29°47′12″N 95°23′27″W﻿ / ﻿29.7866°N 95.3909°W﻿...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>5</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>1660272</td>\n",
       "      <td>1445632</td>\n",
       "      <td>+14.85%</td>\n",
       "      <td>5176</td>\n",
       "      <td>13406</td>\n",
       "      <td>3120</td>\n",
       "      <td>100</td>\n",
       "      <td>33°34′20″N 112°05′24″W﻿ / ﻿33.5722°N 112.0901°...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Phoenix,_Arizona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            City 2018rank       State 2018estimate 2010Census   Change  \\\n",
       "0  New York City        1    New York      8398748    8175133   +2.74%   \n",
       "1    Los Angeles        2  California      3990456    3792621   +5.22%   \n",
       "2        Chicago        3    Illinois      2705994    2695598   +0.39%   \n",
       "3        Houston        4       Texas      2325502    2100263  +10.72%   \n",
       "4        Phoenix        5     Arizona      1660272    1445632  +14.85%   \n",
       "\n",
       "  2016 land area (sq miles) 2016 land area (sq km)  \\\n",
       "0                      3015                   7809   \n",
       "1                      4687                   1139   \n",
       "2                      2273                   5887   \n",
       "3                      6375                  16511   \n",
       "4                      5176                  13406   \n",
       "\n",
       "  2016 population density (sq miles) 2016 population density (sq km)  \\\n",
       "0                              28317                           10933   \n",
       "1                               8484                             376   \n",
       "2                              11900                            4600   \n",
       "3                               3613                            1395   \n",
       "4                               3120                             100   \n",
       "\n",
       "                                            Location  \\\n",
       "0  40°39′49″N 73°56′19″W﻿ / ﻿40.6635°N 73.9387°W﻿...   \n",
       "1  34°01′10″N 118°24′39″W﻿ / ﻿34.0194°N 118.4108°...   \n",
       "2  41°50′15″N 87°40′54″W﻿ / ﻿41.8376°N 87.6818°W﻿...   \n",
       "3  29°47′12″N 95°23′27″W﻿ / ﻿29.7866°N 95.3909°W﻿...   \n",
       "4  33°34′20″N 112°05′24″W﻿ / ﻿33.5722°N 112.0901°...   \n",
       "\n",
       "                                             Link  \n",
       "0     https://en.wikipedia.org/wiki/New_York_City  \n",
       "1       https://en.wikipedia.org/wiki/Los_Angeles  \n",
       "2           https://en.wikipedia.org/wiki/Chicago  \n",
       "3           https://en.wikipedia.org/wiki/Houston  \n",
       "4  https://en.wikipedia.org/wiki/Phoenix,_Arizona  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. cities_hist tables\n",
    "Visits the individual wikipedia links of cities from 'Link' column of cities_main and fetches the historical population trend.  The picture below displays population trend of Mesa, Atlanta, one of the top 314 cities from https://en.wikipedia.org/wiki/Mesa,_Arizona\n",
    "\n",
    "![alt text](sub.png \"Population Trend of Mesa, Atlanta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: get_citytable\n",
    "Parameters:\n",
    "    city_url: string \n",
    "Returns:\n",
    "    BeautifulSoup object\n",
    "Description:\n",
    "    scrapes BeautifulSoup object representing html table with class 'toccolours'  \n",
    "    and row text 'Historical Population' from the wikipedia url)\n",
    "'''\n",
    "def get_citytable(city_url):\n",
    "    url = city_url\n",
    "    req = urllib.request.urlopen(url)\n",
    "    article = req.read().decode()\n",
    "\n",
    "    soup = BeautifulSoup(article, 'html.parser')\n",
    "    tables = soup.find_all('table', class_='toccolours')\n",
    "    tab=[]\n",
    "    for table in tables:\n",
    "        if table.find('tr').text.strip()=='Historical population':\n",
    "            tab=table\n",
    "            break\n",
    "    return tab\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: get_cityheaders\n",
    "Parameters:\n",
    "    table: BeautifulSoup Object\n",
    "Returns:\n",
    "    table headers list\n",
    "Description:\n",
    "    scrapes table headers list from BeautifulSoup object representing html table with class 'toccolours'  \n",
    "    and row text 'Historical Population' from the wikipedia url)\n",
    "'''\n",
    "def get_cityheaders(table):\n",
    "    ths = table.find_all('tr')[1].find_all('th')\n",
    "    headers=[]\n",
    "    for th in ths:\n",
    "        headers.append(th.text.strip())\n",
    "    for elem in range(len(headers)):\n",
    "        if headers[elem]=='Census':\n",
    "            headers[elem]='Year'\n",
    "        if headers[elem]=='%±':\n",
    "            headers[elem]='±%'\n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: get_city_histdata\n",
    "Parameters:\n",
    "    table: BeautifulSoup Object\n",
    "Returns:\n",
    "    list of list\n",
    "Description:\n",
    "    scrapes table data list from BeautifulSoup object representing html table with class 'toccolours'  \n",
    "    and row text 'Historical Population' from the wikipedia url)\n",
    "'''\n",
    "def get_city_histdata(table):\n",
    "    table_data=[]\n",
    "    trs=table.find_all('tr')\n",
    "    for tr in trs[2:]:\n",
    "        #colspan=int(tr.attrs['colspan'])\n",
    "        elems=tr.find_all()\n",
    "        if not elems:\n",
    "            continue\n",
    "        row=[]\n",
    "        for elem in elems:\n",
    "            if elem.find('a'):\n",
    "                ''#print(elem.text.strip())\n",
    "            else:\n",
    "                elem_text=elem.text.strip()\n",
    "                if elem.find('sup'):\n",
    "                    elem_text=elem_text.replace(elem.find('sup').text.strip(),\"\")\n",
    "                row.append(elem_text)\n",
    "        table_data.append(row)\n",
    "    return table_data[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Function: get_city_hist_df\n",
    "Parameters:\n",
    "    city_name: Name of the city\n",
    "    headers: headers list\n",
    "    data: historical data list of lists\n",
    "Returns:\n",
    "    dataframe\n",
    "Description:\n",
    "    combines headers and data into a single dataframe\n",
    "    adds another column city_name to the data frame\n",
    "'''\n",
    "def get_city_hist_df(city_name,headers,table_data):\n",
    "    city_hist=pd.DataFrame(table_data,columns=headers)\n",
    "    city_hist['city_name']=city_name\n",
    "    return city_hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Historical Population scraping utility\n",
    "This program fetches links and city_name from the cities_main table and fetches 'Historical population' from the respective  \n",
    "In case, the the information is missing, the scraping utility will print the city name for which the population is not found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Historical Population not found for Anaheim\n",
      "Historical Population not found for Newark\n",
      "Historical Population not found for Cedar Rapids\n",
      "Historical Population not found for Clinton\n"
     ]
    }
   ],
   "source": [
    "cities_hist=pd.DataFrame()\n",
    "for i in range(314):\n",
    "    city_name=cities_main[['City','Link']].iloc[i]['City']\n",
    "    'print(city_name)'\n",
    "    link=cities_main[['City','Link']].iloc[i]['Link']\n",
    "    city_table=get_citytable(link)\n",
    "    if city_table:\n",
    "        table_headers=get_cityheaders(city_table)\n",
    "        table_data=get_city_histdata(city_table)\n",
    "        city_hist=get_city_hist_df(city_name,table_headers,table_data)\n",
    "        cities_hist=pd.concat([cities_hist,city_hist], ignore_index=True, sort=True)\n",
    "    else:\n",
    "        print('Historical Population not found for '+str(city_name))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Cleaning and Rearrangement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stripAlpha(cities_hist,['Pop.'])            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_hist=cities_hist.drop(columns='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_hist=cities_hist[['city_name', 'Year', 'Pop.', '±%']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Pop.</th>\n",
       "      <th>±%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New York City</td>\n",
       "      <td>1698</td>\n",
       "      <td>4937</td>\n",
       "      <td>—</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York City</td>\n",
       "      <td>1712</td>\n",
       "      <td>5840</td>\n",
       "      <td>+18.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York City</td>\n",
       "      <td>1723</td>\n",
       "      <td>7248</td>\n",
       "      <td>+24.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>New York City</td>\n",
       "      <td>1737</td>\n",
       "      <td>10664</td>\n",
       "      <td>+47.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New York City</td>\n",
       "      <td>1746</td>\n",
       "      <td>11717</td>\n",
       "      <td>+9.9%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       city_name  Year   Pop.      ±%\n",
       "0  New York City  1698   4937       —\n",
       "1  New York City  1712   5840  +18.3%\n",
       "2  New York City  1723   7248  +24.1%\n",
       "3  New York City  1737  10664  +47.1%\n",
       "4  New York City  1746  11717   +9.9%"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities_hist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save csv\n",
    "Save the two tables into the csv format\n",
    "The tables can be loaded into Bigtable of GCP and can be merged joined based on the city_name key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_hist.to_csv('cities_hist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities_main.to_csv('cities_main.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
